{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import permutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drct = '/home/somayeh/Documents/Career/Data_Incubator/Capstone/Data/'\n",
    "result_drct = '/home/somayeh/Documents/Career/Data_Incubator/Capstone/Result/'\n",
    "filename2 = 'cpc_current.tsv'\n",
    "filename3 = 'uspatentcitation.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Data Preparation:__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Extracting patent IDs and issuance year and saving locally per year. (\n",
    "patent_id is citing citation_id. year is for citation_id)<br>\n",
    "Results are stored in:\n",
    "<br>\n",
    "./patent_yr/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yr(yr):\n",
    "    print(yr)\n",
    "    df_chunk = pd.read_csv(data_drct+filename3,sep='\\t',header=0, chunksize=1000000)\n",
    "    patent_list = []  \n",
    "    for cnt, chunk in enumerate(df_chunk):\n",
    "#         print(cnt)\n",
    "        chunk['year'] = pd.to_datetime(chunk['date'], format = '%Y-%M-%d', errors='coerce').dt.year\n",
    "        chunk['year'] = chunk['year'].fillna(0).astype(int)\n",
    "        chunk = chunk[(chunk.year==yr)]\n",
    "        patent_list.append(chunk[['citation_id','year']].drop_duplicates(keep='first'))\n",
    "    df = pd.concat(patent_list)\n",
    "    df.drop_duplicates(keep='first')\n",
    "    drc = result_drct+'/patent_yr/'\n",
    "    if not os.path.exists(drc):\n",
    "        os.makedirs(drc)\n",
    "    fname = drc+str(yr)+'.pkl'\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "for yr in range(2018,2020):\n",
    "    write_yr(yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I need the patent_id, citation_id, and year. For that, I am creating another set of yearly dataframes containing all those information (as below).\n",
    "<br>\n",
    "Rsults are stoed in: <br>\n",
    "./patent_citation_yr/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yr2(yr):\n",
    "    print(yr)\n",
    "    df_chunk = pd.read_csv(data_drct+filename3,sep='\\t',header=0, chunksize=1000000)\n",
    "    patent_list = []  \n",
    "    for cnt, chunk in enumerate(df_chunk):\n",
    "        print(cnt)\n",
    "        chunk['year'] = pd.to_datetime(chunk['date'], format = '%Y-%M-%d', errors='coerce').dt.year\n",
    "        chunk['year'] = chunk['year'].fillna(0).astype(int)\n",
    "        chunk = chunk[(chunk.year==yr)]\n",
    "        patent_list.append(chunk[['patent_id','citation_id','year']])\n",
    "    df = pd.concat(patent_list)\n",
    "    drc = result_drct+'/patent_citation_yr/'\n",
    "    if not os.path.exists(drc):\n",
    "        os.makedirs(drc)\n",
    "    fname = drc+str(yr)+'.pkl'\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yr in range(1992,2020):\n",
    "    write_yr2(yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I take group IDs for patents and save it as \"patent_id_group\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_group():\n",
    "    df_chunk = pd.read_csv(data_drct+filename2,sep='\\t',header=0, chunksize=1000000)\n",
    "    patent_list2 = []  \n",
    "    for cnt, chunk in enumerate(df_chunk):\n",
    "        print(cnt)\n",
    "        patent_list2.append(chunk[['patent_id','group_id']])\n",
    "\n",
    "    patent_id_group = pd.concat(patent_list2)\n",
    "    del patent_list2  \n",
    "    fname = result_drct+'patent_id_group.pkl'\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(patent_id_group, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_id_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
